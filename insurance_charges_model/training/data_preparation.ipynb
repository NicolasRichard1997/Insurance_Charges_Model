{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import inf, nan\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import featuretools as ft\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from insurance_charges_model.prediction.transformers import DFSTransformer\n",
    "from insurance_charges_model.prediction.transformers import InfinityToNaNTransformer\n",
    "from insurance_charges_model.prediction.transformers import IntToFloatTransformer\n",
    "from insurance_charges_model.prediction.transformers import BooleanTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Synthesis\n",
    "We'll be using the featuretools package to do feature engineering.\n",
    "\n",
    "An EntitySet is an object that we will give to the featuretools package in order to do feature engineering. An entitySet denotes the features of specific \"entity\" in the real world. In this case, we will work with only one type of entity: \"transactions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entityset = ft.EntitySet(id=\"Transactions\")\n",
    "entityset = entityset.entity_from_dataframe(entity_id=\"Transactions\",\n",
    "                                            dataframe=df,\n",
    "                                            make_index=True,\n",
    "                                            index=\"index\")\n",
    "\n",
    "entityset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a list of variables associated with the EntitySet we just created\n",
    "entityset[\"Transactions\"].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined an EntitySet for our data, we'll ask the featuretools package to create some features for us. The package defines a set of \"primitives\" that are able to create new features by processing the features that already exist in the EntitySet.\n",
    "\n",
    "We are also going to ignore the categorical and boolean features in the dataset because they don't play well with the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe, features = ft.dfs(entityset=entityset,\n",
    "                                     target_entity=\"Transactions\",\n",
    "                                     trans_primitives=[\"add_numeric\", \"subtract_numeric\",\n",
    "                                                       \"multiply_numeric\", \"divide_numeric\",\n",
    "                                                       \"greater_than\", \"less_than\"],\n",
    "                                     # ignoring some variables\n",
    "                                     ignore_variables={\"Transactions\": [\"sex\", \"smoker\", \"region\", \"charges\"]})\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have created {} new features from the original {} features.\".format(len(features), len(df.columns) - 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature_dataframe variable now contains the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Features using Deep Feature Synthesis\n",
    "\n",
    "Now we can create a Transformer that we can use later to create the features, given samples of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_transformer = DFSTransformer(\"Transactions\",\n",
    "                                 trans_primitives=[\"add_numeric\", \"subtract_numeric\",\n",
    "                                                   \"multiply_numeric\", \"divide_numeric\",\n",
    "                                                   \"greater_than\", \"less_than\"],\n",
    "                                 ignore_variables={\"Transactions\": [\"sex\", \"smoker\", \"region\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the transformer\n",
    "test_df = pd.DataFrame([[65, \"male\", 12.5, 0, \"yes\", \"southwest\"],\n",
    "                        [75, \"female\", 78.770, 1, \"no\", \"southeast\"]],\n",
    "                       columns=[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"])\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "dfs_transformer_copy = deepcopy(dfs_transformer)\n",
    "\n",
    "dfs_transformer_copy.fit(test_df)\n",
    "new_df = dfs_transformer_copy.transform(test_df)\n",
    "\n",
    "if len(new_df.columns) != 30:\n",
    "    raise ValueError(\"Unexpected number of columns found in the dataframe.\")\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Transformer for inf Values\n",
    "\n",
    "Some of the features created by the featuretools package have a value of 'inf'. We'll create a transformer that maps these values to 0.0 to allow the models to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinity_transformer = InfinityToNaNTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the transformer\n",
    "inpt = [[1.0], [inf], [1.0]]\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "infinity_transformer_copy = deepcopy(infinity_transformer)\n",
    "\n",
    "infinity_transformer_copy.fit(inpt)\n",
    "result = infinity_transformer_copy.transform(inpt)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to handle the NaN values, we'll use a SimpleImputer that will fill in the missing value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the transformer\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "simple_imputer_copy = deepcopy(simple_imputer)\n",
    "\n",
    "simple_imputer_copy.fit(result)\n",
    "\n",
    "test_df = [[np.nan, 2, 3], [4, np.nan, 6], [10, np.nan, 9]]\n",
    "print(simple_imputer_copy.transform(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SimpleImputer transformer has problems with imputing values that are not floats when using the 'mean' strategy. To fix this, we'll create a transformer that will convert all integer columns into floating point columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_float_transformer = IntToFloatTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the transformer\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "int_to_float_transformer_copy = deepcopy(int_to_float_transformer)\n",
    "\n",
    "int_to_float_transformer_copy.fit(result)\n",
    "\n",
    "test_df = [[2, 3.0], [4, 6.0], [10, 9.0]]\n",
    "print(int_to_float_transformer_copy.transform(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll put the IntToFloatTransformer, DFSTransformer, InfinityToNaNTransformer, and SimpleImputer transformers into a Pipeline so they'll all work together as a unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_pipeline = Pipeline([\n",
    "    (\"dfs_transformer\", dfs_transformer),\n",
    "    (\"int_to_float_transformer\", int_to_float_transformer),\n",
    "    (\"infinity_transformer\", infinity_transformer),\n",
    "    (\"simple_imputer\", simple_imputer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the transformer\n",
    "test_df = pd.DataFrame([[65, 12.5, 0],\n",
    "                        [75, 78.770, 1]],\n",
    "                       columns=[\"age\", \"bmi\", \"children\"])\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "dfs_pipeline_copy = deepcopy(dfs_pipeline)\n",
    "\n",
    "dfs_pipeline_copy.fit(test_df)\n",
    "new_df = dfs_pipeline_copy.transform(test_df)\n",
    "\n",
    "if len(new_df[0]) != 30:\n",
    "    raise ValueError(\"Unexpected number of columns found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Boolean Features\n",
    "\n",
    "We'll create a transformer that is able to convert the string in the 'smoker' feature to a boolean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_transformer = BooleanTransformer(true_value=\"yes\", false_value=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the transformer\n",
    "test_df = pd.DataFrame([[\"yes\"], [\"no\"], [\"yes\"]],\n",
    "                       columns=[\"smoker\"])\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "boolean_transformer_copy = deepcopy(boolean_transformer)\n",
    "\n",
    "boolean_transformer_copy.fit(test_df)\n",
    "result = boolean_transformer_copy.transform(test_df)\n",
    "\n",
    "if (result != np.array([[True], [False], [True]])).all():\n",
    "    raise ValueError(\"Unexpected values found in array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Features\n",
    "\n",
    "Next, we'll create an encoder that will encode the categorical features. The categorical features that we will encode will be 'sex' and 'region'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the transformer\n",
    "test_df = pd.DataFrame([[\"southwest\"], [\"northeast\"], [\"southwest\"]],\n",
    "                       columns=[\"region\"])\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "ordinal_encoder_copy = deepcopy(ordinal_encoder)\n",
    "\n",
    "ordinal_encoder_copy.fit(test_df)\n",
    "result = ordinal_encoder_copy.transform(test_df)\n",
    "\n",
    "if (result != np.array([[1.0], [0.0], [1.0]])).all():\n",
    "    raise ValueError(\"Unexpected values found in array.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ColumnTransformer\n",
    "\n",
    "Combining all of the preprocessors into one ColumnTransformer that can be used to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(\n",
    "    remainder=\"passthrough\",\n",
    "    transformers=[\n",
    "        (\"dfs_pipeline\", dfs_pipeline, [\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]),\n",
    "        (\"boolean_transformer\", boolean_transformer, [\"smoker\"]),\n",
    "        (\"ordinal_encoder\", ordinal_encoder, [\"sex\", \"region\"])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the ColumnTransformer\n",
    "test_df = pd.DataFrame([[65, \"male\", 12.5, 0, \"yes\", \"southwest\"],\n",
    "                        [75, \"female\", 78.770, 1, \"no\", \"southeast\"]],\n",
    "                       columns=[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"])\n",
    "\n",
    "# copying the transformer object in order to fit and test it\n",
    "column_transformer_copy = deepcopy(column_transformer)\n",
    "\n",
    "column_transformer_copy.fit(test_df)\n",
    "\n",
    "result = column_transformer_copy.transform(test_df)\n",
    "\n",
    "if len(result[0]) != 33:  # expecting 33 features to come out of the ColumnTransformer\n",
    "    raise ValueError(\"Unexpected number of columns found in the dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving ColumnTransformer\n",
    "\n",
    "NOTE: the ColumnTransformer object is saved in an UNFITTED state, it will be fitted to the data set later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(column_transformer, \"transformer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
