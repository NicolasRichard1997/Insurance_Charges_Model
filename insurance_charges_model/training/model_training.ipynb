{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "repertory_path = os.path.abspath(os.path.join(current_directory, \"..\", \"..\"))\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(repertory_path + \"/data/insurance.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1049, 7)\n",
      "(289, 7)\n"
     ]
    }
   ],
   "source": [
    "mask = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "training_set = df[mask]\n",
    "\n",
    "testing_set = df[~mask]\n",
    "\n",
    "print(training_set.shape)\n",
    "print(testing_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training and test sets to be used later\n",
    "training_set.to_csv(repertory_path + \"/data/trainning_set.csv\")\n",
    "testing_set.to_csv(repertory_path  + \"/data/testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the feature columns from the target column\n",
    "feature_columns = [\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"]\n",
    "target_column = \"charges\"\n",
    "\n",
    "X_train = training_set[feature_columns]\n",
    "y_train = training_set[target_column]\n",
    "\n",
    "X_test = testing_set[feature_columns]\n",
    "y_test = testing_set[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the preprocessing pipeline we built in the previous notebook\n",
    "transformer = joblib.load(\"transformer.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.  , 27.9 ,  0.  , ...,  1.  ,  0.  ,  3.  ],\n",
       "       [18.  , 33.77,  1.  , ...,  0.  ,  1.  ,  2.  ],\n",
       "       [32.  , 28.88,  0.  , ...,  0.  ,  1.  ,  1.  ],\n",
       "       ...,\n",
       "       [50.  , 30.97,  3.  , ...,  0.  ,  1.  ,  1.  ],\n",
       "       [18.  , 31.92,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [61.  , 29.07,  0.  , ...,  1.  ,  0.  ,  1.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the column transformer\n",
    "features = transformer.fit_transform(X_train)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find an Optimal Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_regressor = TPOTRegressor(generations=50,\n",
    "                               population_size=50,\n",
    "                               random_state=42,\n",
    "                               cv=5,\n",
    "                               n_jobs=8,\n",
    "                               verbosity=2,\n",
    "                               early_stop=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 0.11.7 of tpot is outdated. Version 0.12.1 was released Tuesday August 15, 2023.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8652e692c867410c9863cf2f6a74b662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/2550 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -19808483.72365711\n",
      "\n",
      "Generation 2 - Current best internal CV score: -19808483.72365711\n",
      "\n",
      "Generation 3 - Current best internal CV score: -19808483.72365711\n",
      "\n",
      "Generation 4 - Current best internal CV score: -19808483.72365711\n",
      "\n",
      "Generation 5 - Current best internal CV score: -19675663.482693005\n",
      "\n",
      "Generation 6 - Current best internal CV score: -19650335.24863593\n",
      "\n",
      "Generation 7 - Current best internal CV score: -19603367.083949894\n",
      "\n",
      "Generation 8 - Current best internal CV score: -19603367.083949894\n",
      "\n",
      "Generation 9 - Current best internal CV score: -19539883.983150538\n",
      "\n",
      "Generation 10 - Current best internal CV score: -19539883.983150538\n",
      "\n",
      "Generation 11 - Current best internal CV score: -19539883.983150538\n",
      "\n",
      "Generation 12 - Current best internal CV score: -19539883.983150538\n",
      "\n",
      "Generation 13 - Current best internal CV score: -19539883.983150538\n",
      "\n",
      "Generation 14 - Current best internal CV score: -19539883.983150538\n",
      "\n",
      "Generation 15 - Current best internal CV score: -19537499.77038715\n",
      "\n",
      "Generation 16 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 17 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 18 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 19 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 20 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 21 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 22 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 23 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 24 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 25 - Current best internal CV score: -19494400.98960331\n",
      "\n",
      "Generation 26 - Current best internal CV score: -19478979.44393432\n",
      "\n",
      "Generation 27 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 28 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 29 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 30 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 31 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 32 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 33 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 34 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 35 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 36 - Current best internal CV score: -19468060.908316325\n",
      "\n",
      "Generation 37 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 38 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 39 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 40 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 41 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 42 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 43 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 44 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 45 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 46 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "Generation 47 - Current best internal CV score: -19467421.920885034\n",
      "\n",
      "The optimized pipeline was not improved after evaluating 10 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: RandomForestRegressor(StandardScaler(VarianceThreshold(input_matrix, threshold=0.1)), bootstrap=True, max_features=0.9000000000000001, min_samples_leaf=18, min_samples_split=13, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "tpot_regressor = tpot_regressor.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline\n",
    "\n",
    "Now that we have an optimal pipeline created by TPOT we will be adding our own preprocessors to it. To do this we'll need to have an unfitted pipeline object.\n",
    "\n",
    "To create an unfitted pipeline from the fitted pipeline that we already have, we'll clone the pipeline object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('variancethreshold', VarianceThreshold(threshold=0.1)),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(max_features=0.9000000000000001,\n",
       "                                       min_samples_leaf=18,\n",
       "                                       min_samples_split=13,\n",
       "                                       random_state=42))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfitted_tpot_regressor = clone(tpot_regressor.fitted_pipeline_)\n",
    "\n",
    "unfitted_tpot_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can build the same pipeline that was found by the TPOT package, we'll add our own preprocessors to the pipeline. This will ensure that the final pipeline will accept the features in the original dataset and will process the features correctly.\n",
    "\n",
    "We'll compose the preprocessing pipeline and the tpot pipeline into one pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"transformer\", transformer),\n",
    "    (\"tpot_pipeline\", unfitted_tpot_regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('dfs_pipeline',\n",
       "                                                  Pipeline(steps=[('dfs_transformer',\n",
       "                                                                   DFSTransformer(ignore_variables={'Transactions': ['sex',\n",
       "                                                                                                                     'smoker',\n",
       "                                                                                                                     'region']},\n",
       "                                                                                  target_entity='Transactions',\n",
       "                                                                                  trans_primitives=['add_numeric',\n",
       "                                                                                                    'subtract_numeric',\n",
       "                                                                                                    'multiply_numeric',\n",
       "                                                                                                    'divide_numeric',\n",
       "                                                                                                    'greater_than',\n",
       "                                                                                                    'less_...\n",
       "                                                  BooleanTransformer(),\n",
       "                                                  ['smoker']),\n",
       "                                                 ('ordinal_encoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['sex', 'region'])])),\n",
       "                ('tpot_pipeline',\n",
       "                 Pipeline(steps=[('variancethreshold',\n",
       "                                  VarianceThreshold(threshold=0.1)),\n",
       "                                 ('standardscaler', StandardScaler()),\n",
       "                                 ('randomforestregressor',\n",
       "                                  RandomForestRegressor(max_features=0.9000000000000001,\n",
       "                                                        min_samples_leaf=18,\n",
       "                                                        min_samples_split=13,\n",
       "                                                        random_state=42))]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model With Single Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24625.65374441])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the ColumnTransformer\n",
    "test_df = pd.DataFrame([[65, \"male\", 12.5, 0, \"yes\", \"southwest\"]],\n",
    "                       columns=[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"])\n",
    "\n",
    "\n",
    "result = model.predict(test_df)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
